#load library============
library(tidyverse)
library(MendelianRandomization)
library(R2jags)
library(BWMR)
#library(MRcML)
library(parallel)
library(pbapply)
library(MR.Corr2)
Rcpp::sourceCpp("/Users/fengsihao/Desktop/Dr.Chen/sihao/fastlm.cpp")
source("/Users/fengsihao/paper_105/mr_horse.R")
source("/Users/fengsihao/paper_105/BWMR_updated.R")


#data generation========
##calculate F-statistics=========
calculate_f_statistics <- function(beta, se, n = NULL) {
  # Individual F-statistics
  f_individual <- (beta / se)^2
  
  # Mean F-statistic
  f_mean <- mean(f_individual, na.rm = TRUE)
  
  # Effective F-statistic (accounting for correlation between SNPs)
  # Using I^2 statistic approach
  Q <- sum((beta / se)^2)
  df <- length(beta) - 1
  I2 <- max(0, (Q - df) / Q)
  f_effective <- f_mean * (1 - I2)
  
  # Proportion of weak instruments (F < 10)
  prop_weak <- mean(f_individual < 10, na.rm = TRUE)
  prop_strong <- mean(f_individual >= 10, na.rm = TRUE)
  
  return(list(
    f_individual = f_individual,
    f_mean = f_mean,
    f_median = f_median,
    f_min = f_min,
    f_conditional = f_conditional,
    f_effective = f_effective,
    prop_weak = prop_weak,
    prop_strong = prop_strong
  ))
}

##generate individual data========
data_generation <- function(ng, nx, ny,
                            a_f = 0.1, b_f = 0.3,
                            a_beta_gx = 0.1, b_beta_gx = 0.2,
                            a_beta_uy = 0.1, b_beta_uy = 0.2,
                            a_beta_uxy = 0.1, b_beta_uxy = 0.2,
                            theta = 0.1,
                            a_alpha_gy = 0.2, b_alpha_gy = 0.3, 
                            gamma_ux = 1, gamma_uy = 1,
                            prop_valid = 0.5,
                            prop_uhp = 0.1,
                            prop_chp_uy = 0.1,
                            prop_chp_uxy = 0.1) {
  
  
  # Ensure proportions sum to <= 1
  total_prop <- prop_valid + prop_uhp + prop_chp_uy + prop_chp_uxy
  if(total_prop > 1) {
    warning("Proportions sum to > 1, scaling down proportionally")
    scale_factor <- 1 / total_prop
    prop_valid <- prop_valid * scale_factor
    prop_uhp <- prop_uhp * scale_factor
    prop_chp_uy <- prop_chp_uy * scale_factor
    prop_chp_uxy <- prop_chp_uxy * scale_factor
  }
  
  # Genotypes
  f <- runif(ng, a_f, b_f)
  gx <- replicate(nx, rbinom(n = ng, size = 2, prob = f))
  gy <- replicate(ny, rbinom(n = ng, size = 2, prob = f))
  gx <- t(apply(gx, 1, function(x) scale(x)[,1]))
  gy <- t(apply(gy, 1, function(x) scale(x)[,1]))
  gx[is.na(gx)] <- 0
  gy[is.na(gy)] <- 0
  
  # Assign SNP categories
  n_valid <- floor(prop_valid * ng)
  n_uhp <- floor(prop_uhp * ng)
  n_uy <- floor(prop_chp_uy * ng)
  n_uxy <- floor(prop_chp_uxy * ng)
  
  total_assigned <- n_valid + n_uhp + n_uy + n_uxy
  if(total_assigned > ng) {
    scale_factor <- ng / total_assigned
    n_valid <- floor(n_valid * scale_factor)
    n_uhp <- floor(n_uhp * scale_factor)
    n_uy <- floor(n_uy * scale_factor)
    n_uxy <- floor(n_uxy * scale_factor)
  }
  
  snp_assignment <- sample(1:ng, ng, replace = FALSE)
  # 修复：正确地分配索引，避免 NA
  crnt_idx <- 1
  
  # Valid SNPs
  if(n_valid > 0) {
    valid_ids <- snp_assignment[crnt_idx:(crnt_idx + n_valid - 1)]
    crnt_idx <- crnt_idx + n_valid
  } else {
    valid_ids <- c()
  }
  
  # uncorrelated  
  if(n_uhp > 0) {
    uhp_ids <- snp_assignment[crnt_idx:(crnt_idx + n_uhp - 1)]
    crnt_idx <- crnt_idx + n_uhp
  } else {
    uhp_ids <- c()
  }
  
  # correlated uy
  if(n_uy > 0) {
    uy_ids <- snp_assignment[crnt_idx:(crnt_idx + n_uy - 1)]
    crnt_idx <- crnt_idx + n_uy  
  } else {
    uy_ids <- c()
  }
  
  # correlated uxy
  if(n_uxy > 0) {
    uxy_ids <- snp_assignment[crnt_idx:(crnt_idx + n_uxy - 1)]
    crnt_idx <- crnt_idx + n_uxy
  } else {
    uxy_ids <- c()
  }
  
  # remaining
  if(crnt_idx <= ng) {
    remaining_ids <- snp_assignment[crnt_idx:ng]
    valid_ids <- c(valid_ids, remaining_ids)
  }
  
  # Generate effect sizes
  beta_gx <- runif(ng, a_beta_gx, b_beta_gx) * sample(c(-1, 1), ng, replace = TRUE)
  
  # uhp
  alpha_gy <- rep(0, ng)
  if(length(uhp_ids) > 0) {
    alpha_gy[uhp_ids] <- runif(length(uhp_ids), a_alpha_gy, b_alpha_gy) * sample(c(-1, 1), length(uhp_ids), replace = TRUE)
  }
  
  # chp throught u1
  beta_uy <- rep(0, ng)
  if(length(uy_ids) > 0) {
    beta_uy[uy_ids] <- runif(length(uy_ids), a_beta_uy, b_beta_uy) * sample(c(-1, 1), length(uy_ids), replace = TRUE)
  }
  # chp through u2
  beta_uxy <- rep(0, ng)
  if(length(uxy_ids) > 0) {
    beta_uxy[uxy_ids] <- runif(length(uxy_ids), a_beta_uxy, b_beta_uxy) * sample(c(-1, 1), length(uxy_ids), replace = TRUE)
  }
  
  # Confounders
  U1x <- as.vector(beta_uy %*% gx) + rnorm(nx)
  U1y <- as.vector(beta_uy %*% gy) + rnorm(ny)
  U2x <- as.vector(beta_uxy %*% gx) + rnorm(nx)
  U2y <- as.vector(beta_uxy %*% gy) + rnorm(ny)
  
  # Exposure
  Xx <- as.vector(beta_gx %*% gx) + gamma_ux * U2x + rnorm(nx)
  Xy <- as.vector(beta_gx %*% gy) + gamma_ux * U2y + rnorm(ny)
  
  # Outcome
  Y <- as.vector(alpha_gy %*% gy) + theta * Xy + gamma_uy * (U1y + U2y) + rnorm(ny)
  
  # Calculate heritability
  #h2_exposure <- var(as.vector(beta_gx %*% gx)) / var(Xx)
  #h2_causal <- ifelse(theta != 0, var(theta * Xy) / var(Y), 0)
  #h2_uhp <- var(as.vector(alpha_gy %*% gy)) / var(Y)
  #h2_chp_uy <- (gamma_uy^2 * var(as.vector(beta_uy %*% gy))) / var(Y)
  #h2_chp_uxy <- (gamma_uy^2 * var(as.vector(beta_uxy %*% gy))) / var(Y)
  
  return(list(
    X = Xx, Y = Y, gx = gx, gy = gy,
    true_beta_gx = beta_gx,
    true_alpha_gy = alpha_gy
  ))
}
##generate summary statistics=======
generate_summary_stats <- function(data_individual) {
  m <- nrow(data_individual$gx)
  b_exp <- numeric(m)
  se_exp <- numeric(m)
  b_out <- numeric(m)
  se_out <- numeric(m)
  
  betaGXSS = fastSigLm(data_individual$X, t(data_individual$gx))
  betaGYSS = fastSigLm(data_individual$Y, t(data_individual$gy))
  b_exp = betaGXSS$coef
  se_exp = betaGXSS$std
  b_out = betaGYSS$coef
  se_out = betaGYSS$std 
  
  # F stats
  f_individual <- (b_exp^2) / (se_exp^2)
  f_mean <- mean(f_individual)
  Q <- sum((b_exp / se_exp)^2)
  df <- length(b_exp) - 1
  I2 <- max(0, (Q - df) / Q)
  f_effective <- f_mean * (1 - I2)
  prop_weak <- mean(f_individual < 10, na.rm = TRUE)
  prop_strong <- mean(f_individual >= 10, na.rm = TRUE)
  
  return(list(
    b_exp = b_exp, 
    se_exp = se_exp,
    b_out = b_out, 
    se_out = se_out, 
    f_mean = f_mean,                  
    prop_weak = prop_weak,          
    prop_strong = prop_strong,       
    I2 = I2
  ))
}



#mr-methods
#mr_methods =============================
library(tidyverse)
library(MendelianRandomization)
library(R2jags)
library(BWMR)
source("/Users/fengsihao/paper_105/mr_horse.R")
source("/Users/fengsihao/paper_105/BWMR_updated.R")

#' Perform all MR analyses using standard structure
perform_mr_analyses <- function(b_exp, b_out, se_exp, se_out, nx = 1000, ny = 1000) {
  
  # Initialize results
  results <- list()
  
  # Check for valid inputs
  if(any(is.na(c(b_exp, b_out, se_exp, se_out))) || length(b_exp) < 3) {
    return(list(
      #ivw_fixed = list(beta = NA, se = NA, pvalue = NA),
      ivw_random = list(beta = NA, se = NA, pvalue = NA),
      #median = list(beta = NA, se = NA, pvalue = NA),
      #egger = list(beta = NA, se = NA, pvalue = NA, intercept = NA, intercept_se = NA, intercept_pvalue = NA),
      egger = list(beta = NA, se = NA, pvalue = NA, intercept = NA),
      cml = list(beta = NA, se = NA, pvalue = NA),
      #cml_dp = list(beta = NA, se = NA, pvalue = NA),
      bwmr = list(beta = NA, se = NA, pvalue = NA),
      horse = list(beta = NA, se = NA, pvalue = NA),
      corr2 = list(beta = NA, se = NA, pvalue = NA)
    ))
  }
  
  # Create MR input object FIRST
  mr.obj <- MendelianRandomization::mr_input(bx = b_exp, bxse = se_exp, by = b_out, byse = se_out)
  
  # IVW Fixed Effect
  #IVW_f <- MendelianRandomization::mr_ivw(mr.obj, model = 'fixed')
  #b_ivw_f <- IVW_f@Estimate
  #se_ivw_f <- IVW_f@StdError
  #p_ivw_f <- IVW_f@Pvalue
  #results$ivw_f <- list(beta = b_ivw_f, se = se_ivw_f, pvalue = p_ivw_f)
  
  # IVW Random Effect
  IVW_r <- MendelianRandomization::mr_ivw(mr.obj, model = 'random')
  b_ivw_r <- IVW_r@Estimate
  se_ivw_r <- IVW_r@StdError
  p_ivw_r <- IVW_r@Pvalue
  results$ivw_r <- list(beta = b_ivw_r, se = se_ivw_r, pvalue = p_ivw_r)
  
  # Weighted Median
  #Median <- MendelianRandomization::mr_median(mr.obj, weighting = 'weighted')
  #b_median <- Median@Estimate
  #se_median <- Median@StdError
  #p_median <- Median@Pvalue
  #results$median <- list(beta = b_median, se = se_median, pvalue = p_median)
  
  # MR-Egger
  Egger <- try(MendelianRandomization::mr_egger(mr.obj), silent = TRUE)
  if(class(Egger) != 'try-error' && !is.null(Egger)) {
    b_egger <- Egger@Estimate
    se_egger <- Egger@StdError.Est
    p_egger <- Egger@Pvalue.Est
    int_egger <- Egger@Intercept
  } else {
    b_egger <- se_egger <- p_egger <- NA
    int_egger <- int_se_egger <- int_p_egger <- NA
  }
  results$egger <- list(
    beta = b_egger, se = se_egger, pvalue = p_egger,
    intercept = int_egger
  )
  
  # cML
  cml <- try(MendelianRandomization::mr_cML(mr.obj, MA = TRUE, DP = FALSE, num_pert = 100, n = nx), silent = TRUE)
  if(class(cml) != 'try-error' && !is.null(cml)) {
    b_cml <- cml@Estimate
    se_cml <- cml@StdError
    p_cml <- cml@Pvalue
  } else {
    b_cml <- se_cml <- p_cml <- NA
  }
  results$cml <- list(beta = b_cml, se = se_cml, pvalue = p_cml)
  
  # cML-DP
  #cml_dp <- try(MendelianRandomization::mr_cML(mr.obj, MA = TRUE, DP = TRUE, num_pert = 100, n = nx), silent = TRUE)
  #if(class(cml_dp) != 'try-error' && !is.null(cml_dp)) {
    #b_cml_dp <- cml_dp@Estimate
    #se_cml_dp <- cml_dp@StdError
    #p_cml_dp <- cml_dp@Pvalue
  #} else {
    #b_cml_dp <- se_cml_dp <- p_cml_dp <- NA
  #}
  #results$cml_dp <- list(beta = b_cml_dp, se = se_cml_dp, pvalue = p_cml_dp)
  
  # BWMR
  bwmr_result <- BWMR(gammahat = b_exp, Gammahat = b_out, sigmaX = se_exp, sigmaY = se_out)
  b_bwmr <- bwmr_result$beta
  se_bwmr <- bwmr_result$se_beta
  p_bwmr <- bwmr_result$P_value
  results$bwmr <- list(beta = b_bwmr, se = se_bwmr, pvalue = p_bwmr)
  
  # MR-horse
  D <- data.frame(
    betaX = b_exp,
    betaXse = se_exp,
    betaY = b_out,
    betaYse = se_out
  )
  horse_result <- mr_horse(D)
  if(class(horse_result) != 'try-error' && !is.null(horse_result)) {
    b_horse <- horse_result$MR_Estimate$Estimate
    se_horse <- horse_result$MR_Estimate$SD
    z_horse <- b_horse / se_horse
    p_horse <- 2 * pnorm(-abs(z_horse))
  } else {
    b_horse <- se_horse <- p_horse <- NA
  }
  results$horse <- list(
    beta = b_horse, 
    se = se_horse, 
    pvalue = p_horse
  )
  
  # MR-corr2
  opt_corr <- list(agm = 0.001, bgm = 0.001, aal = 0.001, bal = 0.001,
                   a = 1, b = length(b_exp), maxIter = 4000, thin = 10, burnin = 1000)
  corr2_result <- try(MRcorr(gammah = b_exp, 
                             Gammah = b_out, 
                             se1 = se_exp, 
                             se2 = se_out, 
                             opt = opt_corr), silent = TRUE)
  if(class(corr2_result) != 'try-error' && !is.null(corr2_result)) {
    b_corr2 <- mean(corr2_result$Beta0res)
    se_corr2 <- sd(corr2_result$Beta0res)
    p_corr2 <- 2 * (1 - pnorm(abs(b_corr2/se_corr2)))
  } else {
    b_corr2 <- se_corr2 <- p_corr2 <- NA  
  }
  results$corr2 <- list(beta = b_corr2, se = se_corr2, pvalue = p_corr2)
  
  return(results)
}
#run simulation=====
# run once
run_simulation = function(n_sim = 1,
                          ng = 10,
                          nx = 1000,
                          ny = 1000,
                          theta = 0.1,
                          prop_valid = 1,
                          prop_uhp = 0,
                          prop_chp_uy = 0,
                          prop_chp_uxy = 0) {
  
  # Create necessary directories if they don't exist
  if(!dir.exists("simulation_data")) {
    dir.create("simulation_data", recursive = TRUE)
  }
  if(!dir.exists("simulation_data_sstat")) {
    dir.create("simulation_data_sstat", recursive = TRUE)
  }
  
  # Initialize results storage
  results = list()
  # Progress bar
  pb = txtProgressBar(min = 0, max = n_sim, style = 3)
  
  for (sim_id in 1:n_sim) {
    # Generate individual-level data
    data_ind = data_generation(
      ng = ng, nx = nx, ny = ny,
      theta = theta,
      prop_valid = prop_valid,
      prop_uhp = prop_uhp,
      prop_chp_uy = prop_chp_uy,
      prop_chp_uxy = prop_chp_uxy
    )
    
    # Generate summary statistics
    summ_stats = generate_summary_stats(data_ind)
    
    # Save raw data for first two simulations
    if (sim_id == 1) {
      # Save individual-level data
      # Combine all individual-level data into one dataframe
      raw_data_df <- data.frame(
        snp_id = 1:ng,
        b_exp = summ_stats$b_exp,
        se_exp = summ_stats$se_exp,
        p_exp = 2 * pnorm(-abs(summ_stats$b_exp / summ_stats$se_exp)),
        b_out = summ_stats$b_out,
        se_out = summ_stats$se_out,
        p_out = 2 * pnorm(-abs(summ_stats$b_out / summ_stats$se_out)),
        f_mean = summ_stats$f_mean,
        truePValid = summ_stats$prop_strong
      )
      
      # Save individual-level data
      write.csv(raw_data_df, 
                file = paste0("simulation_data/sim_", sim_id, "_raw_data.csv"),
                row.names = FALSE)
      
      # Also save the effect sizes and other parameters
      params_df <- data.frame(
        snp_id = 1:ng,
        gamma_true = data_ind$true_beta_gx,  
        alpha_true = data_ind$true_alpha_gy, 
        theta_true = theta
      )
      
      write.csv(params_df,
                file = paste0("simulation_data/sim_", sim_id, "_parameters.csv"),
                row.names = FALSE)
      
      # Save summary statistics
      sstat_df <- data.frame(
        snp_id = 1:ng,
        b_exp = summ_stats$b_exp,
        se_exp = summ_stats$se_exp,
        p_exp = 2 * pnorm(-abs(summ_stats$b_exp / summ_stats$se_exp)),
        b_out = summ_stats$b_out,
        se_out = summ_stats$se_out,
        p_out = 2 * pnorm(-abs(summ_stats$b_out / summ_stats$se_out))
      )
      
      write.csv(sstat_df,
                file = paste0("simulation_data_sstat/sim_", sim_id, "_summary_stats.csv"),
                row.names = FALSE)
    }
    
    b_exp = as.numeric(summ_stats$b_exp)
    b_out = as.numeric(summ_stats$b_out)
    se_exp = as.numeric(summ_stats$se_exp)
    se_out = as.numeric(summ_stats$se_out)
    
    mr_results = perform_mr_analyses(b_exp, b_out, se_exp, se_out, nx)
    
    sim_results = list(
      sim_id = sim_id,
      true_theta = theta,
      
      # IVW fixed
      #ivw_f_beta = mr_results$ivw_f$beta,
      #ivw_f_se = mr_results$ivw_f$se,
      #ivw_f_pvalue = mr_results$ivw_f$pvalue,
      
      # IVW random
      ivw_r_beta = mr_results$ivw_r$beta,
      ivw_r_se = mr_results$ivw_r$se,
      ivw_r_pvalue = mr_results$ivw_r$pvalue,
      
      # Median
      #median_beta = mr_results$median$beta,
      #median_se = mr_results$median$se,
      #median_pvalue = mr_results$median$pvalue,
      
      # Egger
      egger_beta = mr_results$egger$beta,
      egger_se = mr_results$egger$se,
      egger_pvalue = mr_results$egger$pvalue,
      
      # cML
      cml_beta = mr_results$cml$beta,
      cml_se = mr_results$cml$se,
      cml_pvalue = mr_results$cml$pvalue,
      
      # cML-DP
      #cml_dp_beta = mr_results$cml_dp$beta,
      #cml_dp_se = mr_results$cml_dp$se,
      #cml_dp_pvalue = mr_results$cml_dp$pvalue,
      
      # BWMR
      bwmr_beta = mr_results$bwmr$beta,
      bwmr_se = mr_results$bwmr$se,
      bwmr_pvalue = mr_results$bwmr$pvalue,
      
      # Horse
      horse_beta = mr_results$horse$beta,
      horse_se = mr_results$horse$se,
      horse_pvalue = mr_results$horse$pvalue,
      
      # MR-Corr2
      corr2_beta = mr_results$corr2$beta,
      corr2_se = mr_results$corr2$se,
      corr2_pvalue = mr_results$corr2$pvalue
    )
    
    results[[sim_id]] = sim_results
    setTxtProgressBar(pb, sim_id)
  }
  
  close(pb)
  
  # Combine all results into a data frame
  results_df = do.call(rbind, results)
  output_dir = "simulation_results"
  if(!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  file_name = sprintf("sim_%d_ng%d_nx%d_ny%d_theta%.1f_propValid%.1f.csv", n_sim, ng, nx, ny, theta, prop_valid)
  file_path = file.path(output_dir, file_name)
  write.csv(results_df, file_path, row.names = FALSE)
  
  return(results_df)
}

#evaluate the results========
library(tidyverse)

# 获取所有CSV文件路径
get_table_files <- function(folder_path) {
  csv_files <- list.files(folder_path, 
                          pattern = "*.csv", 
                          full.names = TRUE, 
                          recursive = TRUE)
  return(csv_files)
}

# 计算估计值汇总统计
get_ests_summary <- function(df, true_theta = 0.1) {
  methods <- list(
    #'IVW (Fixed)' = c('ivw_f_beta', 'ivw_f_se'),
    'IVW (Random)' = c('ivw_r_beta', 'ivw_r_se'),
    #'Weighted Median' = c('median_beta', 'median_se'),
    'MR-Egger' = c('egger_beta', 'egger_se'),
    'CML' = c('cml_beta', 'cml_se'),
    #'CML-DP' = c('cml_dp_beta', 'cml_dp_se'),
    'BWMR' = c('bwmr_beta', 'bwmr_se'),
    'MR-Horse' = c('horse_beta', 'horse_se'),
    'MR-Corr2' = c('corr2_beta', 'corr2_se')
  )
  results <- data.frame()
  
  for (method_name in names(methods)) {
    beta_col <- methods[[method_name]][1]
    se_col <- methods[[method_name]][2]
    
    if (!(beta_col %in% names(df)) || !(se_col %in% names(df))) {
      next
    }
    
    betas <- df[[beta_col]][!is.na(df[[beta_col]])]
    ses <- df[[se_col]][!is.na(df[[se_col]])]
    
    if (length(betas) == 0 || length(ses) == 0) {
      next
    }
    
    # get mean
    mean_estimate <- mean(betas)
    sd_estimate <- sd(betas)
    
    
    # 95% ci
    ci_lower <- betas - 1.96 * ses
    ci_upper <- betas + 1.96 * ses
    coverage <- mean((ci_lower <= true_theta) & (true_theta <= ci_upper))
    
    # save results
    result_row <- data.frame(
      Method = method_name,
      Mean = mean_estimate,
      SD = sd_estimate,
      Cov. = coverage,
      N = length(betas)
    )
    
    results <- rbind(results, result_row)
  }
  
  return(results)
}

# print results
print_results <- function(file_path) {
  fname <- basename(file_path)
  parts <- strsplit(gsub(".csv", "", fname), "_")[[1]]
  
  tryCatch({
    n_sim <- as.integer(parts[2])
    ng <- as.integer(gsub("ng", "", parts[3]))
    nx <- as.integer(gsub("nx", "", parts[4]))
    ny <- as.integer(gsub("ny", "", parts[5]))
    theta <- as.numeric(gsub("theta", "", parts[6]))
    prop_valid <- as.numeric(gsub("propValid", "", parts[7]))
    
    df <- read.csv(file_path)
    cat(sprintf("n_sim=%d, ng=%d, nx=%d, ny=%d, true_theta=%.2f, prop_valid=%.2f, truePValid=%.2f\n",
                n_sim, ng, nx, ny, theta, prop_valid))
    cat(sprintf("data shape: [%d, %d]\n", nrow(df), ncol(df)))
    results <- get_ests_summary(df, true_theta = theta)
    print(results, row.names = FALSE)
    cat("\n")
    
  }, error = function(e) {
    cat(sprintf("Error processing file %s: %s\n", fname, e$message))
  })
}

# analyze all
analyze_all_simulations <- function(folder_path = "simulation_results") {
  # read all files
  csv_files <- get_table_files(folder_path)
  for (file_path in csv_files) {
    cat("Processing:", basename(file_path), "\n")
    cat(paste(rep("-", 60), collapse=""), "\n")
    print_results(file_path)
  }
}

#test examples===============
set.seed(5692)
#test exmaple1==========
#uhp, uxy only
for (prop_valid in c(0.1, 0.5, 0.8, 1.0)) {
  run_simulation(n_sim=10, ng=20, nx=500, ny=500, theta=0.1, prop_valid=prop_valid, prop_chp_uxy=1-prop_valid)
}

#test example2========
#uhp, uy only
for (prop_valid in c(0.1, 0.5, 0.8, 1.0)) {
  run_simulation(n_sim=10, ng=20, nx=500, ny=500, theta=0.1, prop_valid=prop_valid, prop_chp_uy=1-prop_valid)
}

#test example3========
#uhp, equal uxy, uy 
for (prop_valid in c(0.1, 0.5, 0.8, 1.0)) {
  run_simulation(n_sim=10, ng=20, nx=500, ny=500, theta=0.1, prop_valid=prop_valid, prop_chp_uxy=(1-prop_valid)/2, prop_chp_uy=(1-prop_valid)/2)
}

#complete simulations=========
# full1 uhp uxy ng=20
for (prop_valid in c(0.1, 0.3, 0.5, 0.7, 0.9)) {
  run_simulation(n_sim=1000, ng=20, nx=5000, ny=5000, theta=0.1, prop_valid=prop_valid, prop_chp_uxy=1-prop_valid)
}

# full1 uhp uxy ng=100
for (prop_valid in c(0.3, 0.5, 0.7, 0.9)) {
  run_simulation(n_sim=1000, ng=100, nx=5000, ny=5000, theta=0.1, prop_valid=prop_valid, prop_chp_uxy=1-prop_valid)
}

for (prop_valid in c(0.1)) {
  run_simulation(n_sim=1, ng=20, nx=50, ny=50, theta=0.1, prop_valid=prop_valid, prop_chp_uxy=1-prop_valid)
}
